# ollama-chatbot
Creating a ollama-chatbot using API call from Ollama and Streamlit

### Pre-requisites:
- Ollama is downloaded and running on your local instance.
- `ollama pull llama3.2:1b` to download the Llama3.2 1b model- Model is chosen as it can run faster on a chatbot, reducing wait times.

### How to run
`streamlit run streamlit-app.py` to run the streamlit app locally.

For more information and the walkthrough of my code- checkout [my medium post](https://onnyunhui.medium.com/building-a-basic-llm-chat-app-with-streamlit-chat-element-functions-using-only-google-colab-70ab2ce05142)
